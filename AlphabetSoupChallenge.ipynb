{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import our input dataset\n",
    "charity_df = pd.read_csv('charity_data.csv')\n",
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NAMES column from the dataset\n",
    "charity_df = charity_df.drop(['NAME'], axis=1)\n",
    "# charity_df = charity_df.drop(['SPECIAL_CONSIDERATIONS'], axis=1)\n",
    "# charity_df = charity_df.drop(['INCOME_AMT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "charity_cat = charity_df.dtypes[charity_df.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          17\n",
       "AFFILIATION                6\n",
       "CLASSIFICATION            71\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "charity_df[charity_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C2380        1\n",
       "C1245        1\n",
       "C1580        1\n",
       "C1900        1\n",
       "C1370        1\n",
       "Name: CLASSIFICATION, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the CLASSIFICATION value counts\n",
    "class_counts = charity_df.CLASSIFICATION.value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8ce7f91590>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the CLASSIFICATION value counts\n",
    "class_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "Other     6062\n",
       "C1200     4837\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace\n",
    "replace_classification = list(class_counts[class_counts <2000].index)\n",
    "\n",
    "# Replace in DataFrame\n",
    "for classification in replace_classification:\n",
    "    charity_df.CLASSIFICATION = charity_df.CLASSIFICATION.replace(classification, \"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "charity_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          17\n",
       "AFFILIATION                6\n",
       "CLASSIFICATION             4\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "charity_df[charity_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T15        2\n",
       "T29        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the APPLICATION_TYPE value counts\n",
    "application_counts = charity_df.APPLICATION_TYPE.value_counts()\n",
    "application_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8cdf83b750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the APPLICATION_TYPE counts\n",
    "application_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "Other     7262\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace\n",
    "replace_application_type = list(application_counts[application_counts <27000].index)\n",
    "\n",
    "# Replace in DataFrame\n",
    "for app_type in replace_application_type:\n",
    "    charity_df.APPLICATION_TYPE = charity_df.APPLICATION_TYPE.replace(app_type, \"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "charity_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T3  AFFILIATION_CompanySponsored  \\\n",
       "0                     1.0                  0.0                           0.0   \n",
       "1                     0.0                  1.0                           0.0   \n",
       "2                     1.0                  0.0                           1.0   \n",
       "3                     0.0                  1.0                           1.0   \n",
       "4                     0.0                  1.0                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  AFFILIATION_Regional  CLASSIFICATION_C1000  \\\n",
       "0                0.0                   0.0                   1.0   \n",
       "1                0.0                   0.0                   0.0   \n",
       "2                0.0                   0.0                   0.0   \n",
       "3                0.0                   0.0                   0.0   \n",
       "4                0.0                   0.0                   1.0   \n",
       "\n",
       "   CLASSIFICATION_C1200  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                   0.0  ...                0.0                     0.0   \n",
       "1                   0.0  ...                1.0                     0.0   \n",
       "2                   0.0  ...                0.0                     0.0   \n",
       "3                   0.0  ...                0.0                     1.0   \n",
       "4                   0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(charity_df[charity_cat]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(charity_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN  STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0  10520599       1     5000              1                     1.0   \n",
       "1  10531628       1   108590              1                     0.0   \n",
       "2  10547893       1     5000              0                     1.0   \n",
       "3  10553066       1     6692              1                     0.0   \n",
       "4  10556103       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  AFFILIATION_CompanySponsored  \\\n",
       "0                  0.0                           0.0   \n",
       "1                  1.0                           0.0   \n",
       "2                  0.0                           1.0   \n",
       "3                  1.0                           1.0   \n",
       "4                  1.0                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0  ...                0.0                     0.0                       0.0   \n",
       "1  ...                1.0                     0.0                       0.0   \n",
       "2  ...                0.0                     0.0                       0.0   \n",
       "3  ...                0.0                     1.0                       0.0   \n",
       "4  ...                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "charity_df = charity_df.merge(encode_df,left_index=True, right_index=True)\n",
    "charity_df = charity_df.drop(charity_cat,1)\n",
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = charity_df[\"IS_SUCCESSFUL\"].values\n",
    "X = charity_df.drop([\"IS_SUCCESSFUL\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  15\n",
    "hidden_nodes_layer2 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                540       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 677\n",
      "Trainable params: 677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 718us/step - loss: 0.6150 - accuracy: 0.6782\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 0s 585us/step - loss: 0.5900 - accuracy: 0.7037\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 0s 585us/step - loss: 0.5855 - accuracy: 0.7065\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 0s 588us/step - loss: 0.5828 - accuracy: 0.7070\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 696us/step - loss: 0.5805 - accuracy: 0.7084\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 688us/step - loss: 0.5794 - accuracy: 0.7090\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 704us/step - loss: 0.5784 - accuracy: 0.7103\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 755us/step - loss: 0.5776 - accuracy: 0.7107\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 775us/step - loss: 0.5767 - accuracy: 0.7119\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 694us/step - loss: 0.5758 - accuracy: 0.7117\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 665us/step - loss: 0.5751 - accuracy: 0.7126\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 642us/step - loss: 0.5747 - accuracy: 0.7144\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 0s 608us/step - loss: 0.5739 - accuracy: 0.7135\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 0s 587us/step - loss: 0.5737 - accuracy: 0.7134\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 0s 583us/step - loss: 0.5732 - accuracy: 0.7147\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 0s 580us/step - loss: 0.5734 - accuracy: 0.7158\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 0s 609us/step - loss: 0.5729 - accuracy: 0.7149\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 0s 621us/step - loss: 0.5724 - accuracy: 0.7155\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 0s 609us/step - loss: 0.5726 - accuracy: 0.7154\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 665us/step - loss: 0.5721 - accuracy: 0.7165\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 655us/step - loss: 0.5717 - accuracy: 0.7151\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 653us/step - loss: 0.5717 - accuracy: 0.7162\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 648us/step - loss: 0.5710 - accuracy: 0.7174\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 628us/step - loss: 0.5712 - accuracy: 0.7171\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 0s 600us/step - loss: 0.5708 - accuracy: 0.7156\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 0s 593us/step - loss: 0.5701 - accuracy: 0.7168\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 661us/step - loss: 0.5705 - accuracy: 0.7162\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 0s 621us/step - loss: 0.5701 - accuracy: 0.7165\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 645us/step - loss: 0.5700 - accuracy: 0.7166\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 634us/step - loss: 0.5702 - accuracy: 0.7166\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 637us/step - loss: 0.5701 - accuracy: 0.7170\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 658us/step - loss: 0.5690 - accuracy: 0.7173\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 639us/step - loss: 0.5696 - accuracy: 0.7170\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 628us/step - loss: 0.5692 - accuracy: 0.7163\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 0s 614us/step - loss: 0.5691 - accuracy: 0.7180\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 0s 600us/step - loss: 0.5692 - accuracy: 0.7179\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 0s 608us/step - loss: 0.5685 - accuracy: 0.7178\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 0s 601us/step - loss: 0.5685 - accuracy: 0.7173\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 0s 619us/step - loss: 0.5686 - accuracy: 0.7174\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 639us/step - loss: 0.5679 - accuracy: 0.7189\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 0s 619us/step - loss: 0.5683 - accuracy: 0.7185\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 636us/step - loss: 0.5679 - accuracy: 0.7178\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 637us/step - loss: 0.5673 - accuracy: 0.7201\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 641us/step - loss: 0.5679 - accuracy: 0.7190\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 637us/step - loss: 0.5674 - accuracy: 0.7189\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 663us/step - loss: 0.5668 - accuracy: 0.7184\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 813us/step - loss: 0.5672 - accuracy: 0.7189\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5668 - accuracy: 0.7191\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5668 - accuracy: 0.71920s - loss: 0.5717 - \n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 697us/step - loss: 0.5667 - accuracy: 0.7196\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 685us/step - loss: 0.5667 - accuracy: 0.7187\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 649us/step - loss: 0.5664 - accuracy: 0.7190\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 636us/step - loss: 0.5659 - accuracy: 0.7205\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 649us/step - loss: 0.5664 - accuracy: 0.7199\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 637us/step - loss: 0.5662 - accuracy: 0.7201\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 0s 618us/step - loss: 0.5655 - accuracy: 0.7203\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 0s 618us/step - loss: 0.5660 - accuracy: 0.7180\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 639us/step - loss: 0.5656 - accuracy: 0.7203\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 0s 618us/step - loss: 0.5654 - accuracy: 0.7191\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 0s 616us/step - loss: 0.5656 - accuracy: 0.7188\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 643us/step - loss: 0.5654 - accuracy: 0.7218\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 0s 608us/step - loss: 0.5653 - accuracy: 0.7211\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 0s 609us/step - loss: 0.5652 - accuracy: 0.7213\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 0s 618us/step - loss: 0.5656 - accuracy: 0.7190\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 0s 618us/step - loss: 0.5651 - accuracy: 0.7196\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 656us/step - loss: 0.5653 - accuracy: 0.7215\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 692us/step - loss: 0.5651 - accuracy: 0.7215\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 624us/step - loss: 0.5648 - accuracy: 0.7210\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 625us/step - loss: 0.5650 - accuracy: 0.7199\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 644us/step - loss: 0.5649 - accuracy: 0.7201\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 636us/step - loss: 0.5653 - accuracy: 0.7198\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 662us/step - loss: 0.5645 - accuracy: 0.7211\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 632us/step - loss: 0.5643 - accuracy: 0.7204\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 633us/step - loss: 0.5647 - accuracy: 0.7209\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 640us/step - loss: 0.5643 - accuracy: 0.7199\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 649us/step - loss: 0.5644 - accuracy: 0.7206\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 642us/step - loss: 0.5641 - accuracy: 0.7207\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 0s 616us/step - loss: 0.5641 - accuracy: 0.7219\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 0s 616us/step - loss: 0.5639 - accuracy: 0.7215\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 630us/step - loss: 0.5640 - accuracy: 0.7211\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 630us/step - loss: 0.5639 - accuracy: 0.7212\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 642us/step - loss: 0.5641 - accuracy: 0.7206\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 663us/step - loss: 0.5640 - accuracy: 0.7209\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 628us/step - loss: 0.5637 - accuracy: 0.7224\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 641us/step - loss: 0.5639 - accuracy: 0.7224\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 643us/step - loss: 0.5637 - accuracy: 0.7223\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 687us/step - loss: 0.5637 - accuracy: 0.7210\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 627us/step - loss: 0.5638 - accuracy: 0.7222\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 627us/step - loss: 0.5636 - accuracy: 0.7220\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 0s 615us/step - loss: 0.5634 - accuracy: 0.7233\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 0s 607us/step - loss: 0.5637 - accuracy: 0.7220\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 629us/step - loss: 0.5632 - accuracy: 0.7220\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 634us/step - loss: 0.5634 - accuracy: 0.7214\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 647us/step - loss: 0.5638 - accuracy: 0.7210\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 634us/step - loss: 0.5635 - accuracy: 0.7214\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 631us/step - loss: 0.5632 - accuracy: 0.7233\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 639us/step - loss: 0.5633 - accuracy: 0.7221\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 686us/step - loss: 0.5631 - accuracy: 0.7223\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 0s 606us/step - loss: 0.5633 - accuracy: 0.7229\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 629us/step - loss: 0.5632 - accuracy: 0.7217\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5803 - accuracy: 0.7064\n",
      "Loss: 0.5803092122077942, Accuracy: 0.7063556909561157\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the model for greater accuracy\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  30\n",
    "hidden_nodes_layer2 = 16\n",
    "hidden_nodes_layer3 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 30)                1080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,721\n",
      "Trainable params: 1,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 700us/step - loss: 0.6040 - accuracy: 0.6903\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 701us/step - loss: 0.5789 - accuracy: 0.7111\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5767 - accuracy: 0.7127\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 699us/step - loss: 0.5744 - accuracy: 0.7137\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 765us/step - loss: 0.5736 - accuracy: 0.7139\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 674us/step - loss: 0.5721 - accuracy: 0.7147\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 690us/step - loss: 0.5718 - accuracy: 0.7153\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 701us/step - loss: 0.5707 - accuracy: 0.7168\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5701 - accuracy: 0.7160\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 712us/step - loss: 0.5699 - accuracy: 0.7156\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5695 - accuracy: 0.7172\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 709us/step - loss: 0.5692 - accuracy: 0.7174\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 702us/step - loss: 0.5681 - accuracy: 0.7187\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 702us/step - loss: 0.5680 - accuracy: 0.7168\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 667us/step - loss: 0.5680 - accuracy: 0.7171\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 678us/step - loss: 0.5670 - accuracy: 0.7180\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 650us/step - loss: 0.5668 - accuracy: 0.7190\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 670us/step - loss: 0.5662 - accuracy: 0.7182\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 666us/step - loss: 0.5663 - accuracy: 0.7192\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 674us/step - loss: 0.5655 - accuracy: 0.7201\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 678us/step - loss: 0.5658 - accuracy: 0.7199\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 695us/step - loss: 0.5650 - accuracy: 0.7192\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5652 - accuracy: 0.7198\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5647 - accuracy: 0.7194\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5646 - accuracy: 0.7213\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5647 - accuracy: 0.7193\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5641 - accuracy: 0.7207\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 691us/step - loss: 0.5635 - accuracy: 0.7200\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 701us/step - loss: 0.5640 - accuracy: 0.7208\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 697us/step - loss: 0.5631 - accuracy: 0.7229\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 709us/step - loss: 0.5633 - accuracy: 0.7206\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 760us/step - loss: 0.5633 - accuracy: 0.7220\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 658us/step - loss: 0.5622 - accuracy: 0.7223\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 682us/step - loss: 0.5626 - accuracy: 0.7216\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 680us/step - loss: 0.5622 - accuracy: 0.7217\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 682us/step - loss: 0.5623 - accuracy: 0.7222\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 712us/step - loss: 0.5618 - accuracy: 0.7209\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 723us/step - loss: 0.5614 - accuracy: 0.7224\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5614 - accuracy: 0.7229\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5614 - accuracy: 0.7224\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 776us/step - loss: 0.5608 - accuracy: 0.7227\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 789us/step - loss: 0.5610 - accuracy: 0.7226\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 809us/step - loss: 0.5607 - accuracy: 0.7210\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5598 - accuracy: 0.7229\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5607 - accuracy: 0.7223\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5600 - accuracy: 0.7227\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 793us/step - loss: 0.5597 - accuracy: 0.7228\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 789us/step - loss: 0.5594 - accuracy: 0.7235\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5591 - accuracy: 0.7219\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 767us/step - loss: 0.5593 - accuracy: 0.7237\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 818us/step - loss: 0.5591 - accuracy: 0.7238\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5589 - accuracy: 0.7237\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 774us/step - loss: 0.5587 - accuracy: 0.7240\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 767us/step - loss: 0.5586 - accuracy: 0.7248\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5585 - accuracy: 0.7248\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 769us/step - loss: 0.5582 - accuracy: 0.7248\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5581 - accuracy: 0.7233\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5582 - accuracy: 0.7241\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5580 - accuracy: 0.7245\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5577 - accuracy: 0.7247\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5573 - accuracy: 0.7258\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 727us/step - loss: 0.5575 - accuracy: 0.7248\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 723us/step - loss: 0.5570 - accuracy: 0.7247\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5572 - accuracy: 0.7257\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5570 - accuracy: 0.7252\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 693us/step - loss: 0.5571 - accuracy: 0.7255\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 697us/step - loss: 0.5563 - accuracy: 0.7256\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 696us/step - loss: 0.5571 - accuracy: 0.7245\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5563 - accuracy: 0.7249\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5563 - accuracy: 0.7251\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 713us/step - loss: 0.5568 - accuracy: 0.7236\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5560 - accuracy: 0.7254\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 760us/step - loss: 0.5557 - accuracy: 0.7259\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5563 - accuracy: 0.7264\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5555 - accuracy: 0.7255\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5557 - accuracy: 0.7270\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5551 - accuracy: 0.7262\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5551 - accuracy: 0.7277\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 807us/step - loss: 0.5553 - accuracy: 0.7258\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5551 - accuracy: 0.7265\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5549 - accuracy: 0.7264\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5553 - accuracy: 0.7264\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5553 - accuracy: 0.7244\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 705us/step - loss: 0.5550 - accuracy: 0.7262\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 664us/step - loss: 0.5543 - accuracy: 0.7268\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 688us/step - loss: 0.5544 - accuracy: 0.7271\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 681us/step - loss: 0.5540 - accuracy: 0.7259\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 683us/step - loss: 0.5540 - accuracy: 0.7272\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 697us/step - loss: 0.5544 - accuracy: 0.7274\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 694us/step - loss: 0.5534 - accuracy: 0.7278\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 689us/step - loss: 0.5538 - accuracy: 0.7278\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 681us/step - loss: 0.5548 - accuracy: 0.7244\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5535 - accuracy: 0.7257\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 688us/step - loss: 0.5538 - accuracy: 0.7275\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 696us/step - loss: 0.5542 - accuracy: 0.7264\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 697us/step - loss: 0.5534 - accuracy: 0.7261\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 714us/step - loss: 0.5525 - accuracy: 0.7268\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5537 - accuracy: 0.7261\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5534 - accuracy: 0.7269\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5528 - accuracy: 0.7287\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5806 - accuracy: 0.7131\n",
      "Loss: 0.5805785655975342, Accuracy: 0.7131195068359375\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the model for greater accuracy\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  30\n",
    "hidden_nodes_layer2 = 16\n",
    "hidden_nodes_layer3 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\")\n",
    ")\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 30)                1080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,721\n",
      "Trainable params: 1,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5980 - accuracy: 0.6950\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 739us/step - loss: 0.5830 - accuracy: 0.7094\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5798 - accuracy: 0.7116\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 764us/step - loss: 0.5775 - accuracy: 0.7131\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5761 - accuracy: 0.7121\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5746 - accuracy: 0.7135\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5738 - accuracy: 0.7146\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5733 - accuracy: 0.7138\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5720 - accuracy: 0.7144\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5715 - accuracy: 0.7158\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 685us/step - loss: 0.5710 - accuracy: 0.7167\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 701us/step - loss: 0.5703 - accuracy: 0.7162\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 684us/step - loss: 0.5695 - accuracy: 0.7151\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 689us/step - loss: 0.5691 - accuracy: 0.7180\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 701us/step - loss: 0.5683 - accuracy: 0.7179\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 711us/step - loss: 0.5679 - accuracy: 0.7167\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 686us/step - loss: 0.5677 - accuracy: 0.7186\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 686us/step - loss: 0.5670 - accuracy: 0.7187\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 685us/step - loss: 0.5663 - accuracy: 0.7189\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5657 - accuracy: 0.7196\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 758us/step - loss: 0.5656 - accuracy: 0.7194\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5652 - accuracy: 0.7202\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5647 - accuracy: 0.7192\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 727us/step - loss: 0.5643 - accuracy: 0.7204\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5640 - accuracy: 0.7199\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 772us/step - loss: 0.5634 - accuracy: 0.7217\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5630 - accuracy: 0.7215\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 764us/step - loss: 0.5624 - accuracy: 0.7221\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5626 - accuracy: 0.7208\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5616 - accuracy: 0.7219\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5613 - accuracy: 0.7225\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5612 - accuracy: 0.7223\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5606 - accuracy: 0.7240\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 755us/step - loss: 0.5604 - accuracy: 0.7221\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 805us/step - loss: 0.5599 - accuracy: 0.7218\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 770us/step - loss: 0.5597 - accuracy: 0.7217\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 766us/step - loss: 0.5589 - accuracy: 0.7249\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5588 - accuracy: 0.7234\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5587 - accuracy: 0.7233\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5585 - accuracy: 0.7244\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5580 - accuracy: 0.7243\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 715us/step - loss: 0.5576 - accuracy: 0.7231\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5576 - accuracy: 0.7246\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5569 - accuracy: 0.7238\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5568 - accuracy: 0.7246\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 684us/step - loss: 0.5569 - accuracy: 0.7242\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 699us/step - loss: 0.5558 - accuracy: 0.7234\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 708us/step - loss: 0.5559 - accuracy: 0.7240\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 696us/step - loss: 0.5558 - accuracy: 0.7247\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 687us/step - loss: 0.5555 - accuracy: 0.7249\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 694us/step - loss: 0.5549 - accuracy: 0.7247\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 696us/step - loss: 0.5550 - accuracy: 0.7248\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 700us/step - loss: 0.5547 - accuracy: 0.7242\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 711us/step - loss: 0.5547 - accuracy: 0.7260\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 694us/step - loss: 0.5541 - accuracy: 0.7248\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 672us/step - loss: 0.5540 - accuracy: 0.7251\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 713us/step - loss: 0.5537 - accuracy: 0.7260\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 692us/step - loss: 0.5534 - accuracy: 0.7254\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 677us/step - loss: 0.5529 - accuracy: 0.7254\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5529 - accuracy: 0.7263\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 763us/step - loss: 0.5526 - accuracy: 0.7256\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5526 - accuracy: 0.7264\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 775us/step - loss: 0.5525 - accuracy: 0.7266\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5518 - accuracy: 0.7249\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 712us/step - loss: 0.5520 - accuracy: 0.7254\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5515 - accuracy: 0.7266\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 684us/step - loss: 0.5516 - accuracy: 0.7254\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 706us/step - loss: 0.5516 - accuracy: 0.7275\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 712us/step - loss: 0.5510 - accuracy: 0.7271\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5512 - accuracy: 0.7273\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 705us/step - loss: 0.5510 - accuracy: 0.7258\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 708us/step - loss: 0.5505 - accuracy: 0.7271\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5506 - accuracy: 0.7261\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 707us/step - loss: 0.5505 - accuracy: 0.7268\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 704us/step - loss: 0.5501 - accuracy: 0.7279\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 704us/step - loss: 0.5498 - accuracy: 0.7280\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5496 - accuracy: 0.7269\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 1s 723us/step - loss: 0.5502 - accuracy: 0.7273\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 734us/step - loss: 0.5492 - accuracy: 0.7269\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5494 - accuracy: 0.7265\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5493 - accuracy: 0.7271\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 684us/step - loss: 0.5492 - accuracy: 0.7274\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5487 - accuracy: 0.7270\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5487 - accuracy: 0.7275\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5485 - accuracy: 0.7297\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5484 - accuracy: 0.7267\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5484 - accuracy: 0.7274\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 707us/step - loss: 0.5480 - accuracy: 0.7286\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 714us/step - loss: 0.5483 - accuracy: 0.7272\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 701us/step - loss: 0.5477 - accuracy: 0.7295\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 707us/step - loss: 0.5475 - accuracy: 0.7287\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5475 - accuracy: 0.7273\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5477 - accuracy: 0.7287\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 702us/step - loss: 0.5473 - accuracy: 0.7280\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 703us/step - loss: 0.5468 - accuracy: 0.7298\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 707us/step - loss: 0.5466 - accuracy: 0.7290\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 703us/step - loss: 0.5468 - accuracy: 0.7294\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 714us/step - loss: 0.5467 - accuracy: 0.7293\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 711us/step - loss: 0.5468 - accuracy: 0.7290\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 676us/step - loss: 0.5466 - accuracy: 0.7289\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5769 - accuracy: 0.7088\n",
      "Loss: 0.5768993496894836, Accuracy: 0.7088046669960022\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the model for greater accuracy\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  60\n",
    "hidden_nodes_layer2 = 32\n",
    "hidden_nodes_layer3 = 16\n",
    "\n",
    "nn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 60)                2160      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                1952      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,657\n",
      "Trainable params: 4,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5941 - accuracy: 0.7013\n",
      "Epoch 2/500\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5807 - accuracy: 0.7102\n",
      "Epoch 3/500\n",
      "804/804 [==============================] - 1s 723us/step - loss: 0.5780 - accuracy: 0.7114\n",
      "Epoch 4/500\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5751 - accuracy: 0.7130\n",
      "Epoch 5/500\n",
      "804/804 [==============================] - 1s 754us/step - loss: 0.5747 - accuracy: 0.7124\n",
      "Epoch 6/500\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5742 - accuracy: 0.7141\n",
      "Epoch 7/500\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5726 - accuracy: 0.7149\n",
      "Epoch 8/500\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5715 - accuracy: 0.7147\n",
      "Epoch 9/500\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5703 - accuracy: 0.7159\n",
      "Epoch 10/500\n",
      "804/804 [==============================] - 1s 713us/step - loss: 0.5695 - accuracy: 0.7154\n",
      "Epoch 11/500\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5690 - accuracy: 0.7175\n",
      "Epoch 12/500\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5679 - accuracy: 0.7170\n",
      "Epoch 13/500\n",
      "804/804 [==============================] - 1s 723us/step - loss: 0.5674 - accuracy: 0.7178\n",
      "Epoch 14/500\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5668 - accuracy: 0.7192\n",
      "Epoch 15/500\n",
      "804/804 [==============================] - 1s 924us/step - loss: 0.5657 - accuracy: 0.7186\n",
      "Epoch 16/500\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5652 - accuracy: 0.7207\n",
      "Epoch 17/500\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5653 - accuracy: 0.7200\n",
      "Epoch 18/500\n",
      "804/804 [==============================] - 1s 860us/step - loss: 0.5643 - accuracy: 0.7201\n",
      "Epoch 19/500\n",
      "804/804 [==============================] - 1s 807us/step - loss: 0.5641 - accuracy: 0.7208\n",
      "Epoch 20/500\n",
      "804/804 [==============================] - 1s 852us/step - loss: 0.5638 - accuracy: 0.7212\n",
      "Epoch 21/500\n",
      "804/804 [==============================] - 1s 894us/step - loss: 0.5631 - accuracy: 0.7219\n",
      "Epoch 22/500\n",
      "804/804 [==============================] - 1s 836us/step - loss: 0.5628 - accuracy: 0.7201\n",
      "Epoch 23/500\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5621 - accuracy: 0.7205\n",
      "Epoch 24/500\n",
      "804/804 [==============================] - 1s 885us/step - loss: 0.5615 - accuracy: 0.7236\n",
      "Epoch 25/500\n",
      "804/804 [==============================] - 1s 877us/step - loss: 0.5613 - accuracy: 0.7239\n",
      "Epoch 26/500\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5607 - accuracy: 0.7239\n",
      "Epoch 27/500\n",
      "804/804 [==============================] - 1s 886us/step - loss: 0.5601 - accuracy: 0.7231\n",
      "Epoch 28/500\n",
      "804/804 [==============================] - 1s 885us/step - loss: 0.5598 - accuracy: 0.7234\n",
      "Epoch 29/500\n",
      "804/804 [==============================] - 1s 926us/step - loss: 0.5593 - accuracy: 0.7246\n",
      "Epoch 30/500\n",
      "804/804 [==============================] - 1s 846us/step - loss: 0.5590 - accuracy: 0.7247\n",
      "Epoch 31/500\n",
      "804/804 [==============================] - 1s 805us/step - loss: 0.5584 - accuracy: 0.7250\n",
      "Epoch 32/500\n",
      "804/804 [==============================] - 1s 834us/step - loss: 0.5580 - accuracy: 0.7253\n",
      "Epoch 33/500\n",
      "804/804 [==============================] - 1s 933us/step - loss: 0.5575 - accuracy: 0.7260\n",
      "Epoch 34/500\n",
      "804/804 [==============================] - 1s 866us/step - loss: 0.5573 - accuracy: 0.7238\n",
      "Epoch 35/500\n",
      "804/804 [==============================] - 1s 830us/step - loss: 0.5569 - accuracy: 0.7260\n",
      "Epoch 36/500\n",
      "804/804 [==============================] - 1s 812us/step - loss: 0.5563 - accuracy: 0.7261\n",
      "Epoch 37/500\n",
      "804/804 [==============================] - 1s 851us/step - loss: 0.5557 - accuracy: 0.7260\n",
      "Epoch 38/500\n",
      "804/804 [==============================] - 1s 941us/step - loss: 0.5556 - accuracy: 0.7286\n",
      "Epoch 39/500\n",
      "804/804 [==============================] - 1s 830us/step - loss: 0.5555 - accuracy: 0.7275\n",
      "Epoch 40/500\n",
      "804/804 [==============================] - 1s 833us/step - loss: 0.5550 - accuracy: 0.7275\n",
      "Epoch 41/500\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5541 - accuracy: 0.7283\n",
      "Epoch 42/500\n",
      "804/804 [==============================] - 1s 893us/step - loss: 0.5538 - accuracy: 0.7279\n",
      "Epoch 43/500\n",
      "804/804 [==============================] - 1s 943us/step - loss: 0.5534 - accuracy: 0.7271\n",
      "Epoch 44/500\n",
      "804/804 [==============================] - 1s 861us/step - loss: 0.5532 - accuracy: 0.7287\n",
      "Epoch 45/500\n",
      "804/804 [==============================] - 1s 871us/step - loss: 0.5531 - accuracy: 0.7287\n",
      "Epoch 46/500\n",
      "804/804 [==============================] - 1s 835us/step - loss: 0.5524 - accuracy: 0.7284\n",
      "Epoch 47/500\n",
      "804/804 [==============================] - 1s 860us/step - loss: 0.5521 - accuracy: 0.7279\n",
      "Epoch 48/500\n",
      "804/804 [==============================] - 1s 844us/step - loss: 0.5516 - accuracy: 0.7287\n",
      "Epoch 49/500\n",
      "804/804 [==============================] - 1s 825us/step - loss: 0.5518 - accuracy: 0.7286\n",
      "Epoch 50/500\n",
      "804/804 [==============================] - 1s 817us/step - loss: 0.5508 - accuracy: 0.7299\n",
      "Epoch 51/500\n",
      "804/804 [==============================] - 1s 854us/step - loss: 0.5513 - accuracy: 0.7287\n",
      "Epoch 52/500\n",
      "804/804 [==============================] - 1s 854us/step - loss: 0.5504 - accuracy: 0.7305\n",
      "Epoch 53/500\n",
      "804/804 [==============================] - 1s 817us/step - loss: 0.5499 - accuracy: 0.7294\n",
      "Epoch 54/500\n",
      "804/804 [==============================] - 1s 813us/step - loss: 0.5500 - accuracy: 0.7289\n",
      "Epoch 55/500\n",
      "804/804 [==============================] - 1s 815us/step - loss: 0.5490 - accuracy: 0.7303\n",
      "Epoch 56/500\n",
      "804/804 [==============================] - 1s 809us/step - loss: 0.5490 - accuracy: 0.7294\n",
      "Epoch 57/500\n",
      "804/804 [==============================] - 1s 757us/step - loss: 0.5491 - accuracy: 0.7297\n",
      "Epoch 58/500\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5485 - accuracy: 0.7307\n",
      "Epoch 59/500\n",
      "804/804 [==============================] - 1s 758us/step - loss: 0.5477 - accuracy: 0.7305\n",
      "Epoch 60/500\n",
      "804/804 [==============================] - 1s 806us/step - loss: 0.5485 - accuracy: 0.7296\n",
      "Epoch 61/500\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5482 - accuracy: 0.7312\n",
      "Epoch 62/500\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5472 - accuracy: 0.7299\n",
      "Epoch 63/500\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5470 - accuracy: 0.7318\n",
      "Epoch 64/500\n",
      "804/804 [==============================] - 1s 717us/step - loss: 0.5469 - accuracy: 0.7300\n",
      "Epoch 65/500\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5470 - accuracy: 0.7312\n",
      "Epoch 66/500\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5460 - accuracy: 0.7321\n",
      "Epoch 67/500\n",
      "804/804 [==============================] - 1s 710us/step - loss: 0.5464 - accuracy: 0.7302\n",
      "Epoch 68/500\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5457 - accuracy: 0.7317\n",
      "Epoch 69/500\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5454 - accuracy: 0.7320\n",
      "Epoch 70/500\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5455 - accuracy: 0.7324\n",
      "Epoch 71/500\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5451 - accuracy: 0.7310\n",
      "Epoch 72/500\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5444 - accuracy: 0.7316\n",
      "Epoch 73/500\n",
      "804/804 [==============================] - 1s 755us/step - loss: 0.5439 - accuracy: 0.7320\n",
      "Epoch 74/500\n",
      "804/804 [==============================] - 1s 778us/step - loss: 0.5443 - accuracy: 0.7320\n",
      "Epoch 75/500\n",
      "804/804 [==============================] - 1s 772us/step - loss: 0.5442 - accuracy: 0.7331\n",
      "Epoch 76/500\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5437 - accuracy: 0.7329\n",
      "Epoch 77/500\n",
      "804/804 [==============================] - 1s 814us/step - loss: 0.5434 - accuracy: 0.7327\n",
      "Epoch 78/500\n",
      "804/804 [==============================] - 1s 826us/step - loss: 0.5433 - accuracy: 0.7334\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 774us/step - loss: 0.5435 - accuracy: 0.7324\n",
      "Epoch 80/500\n",
      "804/804 [==============================] - 1s 770us/step - loss: 0.5434 - accuracy: 0.7328\n",
      "Epoch 81/500\n",
      "804/804 [==============================] - 1s 769us/step - loss: 0.5424 - accuracy: 0.7346\n",
      "Epoch 82/500\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.5427 - accuracy: 0.7337\n",
      "Epoch 83/500\n",
      "804/804 [==============================] - 1s 775us/step - loss: 0.5429 - accuracy: 0.7327\n",
      "Epoch 84/500\n",
      "804/804 [==============================] - 1s 791us/step - loss: 0.5421 - accuracy: 0.7332\n",
      "Epoch 85/500\n",
      "804/804 [==============================] - 1s 771us/step - loss: 0.5423 - accuracy: 0.7332\n",
      "Epoch 86/500\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5416 - accuracy: 0.7336\n",
      "Epoch 87/500\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5417 - accuracy: 0.7336\n",
      "Epoch 88/500\n",
      "804/804 [==============================] - 1s 799us/step - loss: 0.5414 - accuracy: 0.7331\n",
      "Epoch 89/500\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5411 - accuracy: 0.7341\n",
      "Epoch 90/500\n",
      "804/804 [==============================] - 1s 784us/step - loss: 0.5410 - accuracy: 0.7336\n",
      "Epoch 91/500\n",
      "804/804 [==============================] - 1s 752us/step - loss: 0.5411 - accuracy: 0.7330\n",
      "Epoch 92/500\n",
      "804/804 [==============================] - 1s 771us/step - loss: 0.5407 - accuracy: 0.7353\n",
      "Epoch 93/500\n",
      "804/804 [==============================] - 1s 776us/step - loss: 0.5406 - accuracy: 0.7342\n",
      "Epoch 94/500\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5402 - accuracy: 0.7339\n",
      "Epoch 95/500\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5406 - accuracy: 0.7335\n",
      "Epoch 96/500\n",
      "804/804 [==============================] - 1s 715us/step - loss: 0.5398 - accuracy: 0.7339\n",
      "Epoch 97/500\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5396 - accuracy: 0.7335\n",
      "Epoch 98/500\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5396 - accuracy: 0.7340\n",
      "Epoch 99/500\n",
      "804/804 [==============================] - 1s 709us/step - loss: 0.5394 - accuracy: 0.7340\n",
      "Epoch 100/500\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5393 - accuracy: 0.7352\n",
      "Epoch 101/500\n",
      "804/804 [==============================] - 1s 727us/step - loss: 0.5386 - accuracy: 0.7339\n",
      "Epoch 102/500\n",
      "804/804 [==============================] - 1s 703us/step - loss: 0.5387 - accuracy: 0.7342\n",
      "Epoch 103/500\n",
      "804/804 [==============================] - 1s 723us/step - loss: 0.5381 - accuracy: 0.7360\n",
      "Epoch 104/500\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5381 - accuracy: 0.7347\n",
      "Epoch 105/500\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5377 - accuracy: 0.7354\n",
      "Epoch 106/500\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5382 - accuracy: 0.7351\n",
      "Epoch 107/500\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5378 - accuracy: 0.7353\n",
      "Epoch 108/500\n",
      "804/804 [==============================] - 1s 755us/step - loss: 0.5381 - accuracy: 0.7349\n",
      "Epoch 109/500\n",
      "804/804 [==============================] - 1s 757us/step - loss: 0.5371 - accuracy: 0.7345\n",
      "Epoch 110/500\n",
      "804/804 [==============================] - 1s 753us/step - loss: 0.5369 - accuracy: 0.7352\n",
      "Epoch 111/500\n",
      "804/804 [==============================] - 1s 755us/step - loss: 0.5371 - accuracy: 0.7352\n",
      "Epoch 112/500\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5369 - accuracy: 0.7358\n",
      "Epoch 113/500\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5366 - accuracy: 0.7362\n",
      "Epoch 114/500\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5367 - accuracy: 0.7348\n",
      "Epoch 115/500\n",
      "804/804 [==============================] - 1s 752us/step - loss: 0.5365 - accuracy: 0.7358\n",
      "Epoch 116/500\n",
      "804/804 [==============================] - 1s 771us/step - loss: 0.5366 - accuracy: 0.7351\n",
      "Epoch 117/500\n",
      "804/804 [==============================] - 1s 819us/step - loss: 0.5358 - accuracy: 0.7358\n",
      "Epoch 118/500\n",
      "804/804 [==============================] - 1s 806us/step - loss: 0.5362 - accuracy: 0.7350\n",
      "Epoch 119/500\n",
      "804/804 [==============================] - 1s 805us/step - loss: 0.5360 - accuracy: 0.7350\n",
      "Epoch 120/500\n",
      "804/804 [==============================] - 1s 804us/step - loss: 0.5357 - accuracy: 0.7351\n",
      "Epoch 121/500\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5352 - accuracy: 0.7365\n",
      "Epoch 122/500\n",
      "804/804 [==============================] - 1s 791us/step - loss: 0.5356 - accuracy: 0.7365\n",
      "Epoch 123/500\n",
      "804/804 [==============================] - 1s 778us/step - loss: 0.5348 - accuracy: 0.7369\n",
      "Epoch 124/500\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5351 - accuracy: 0.7353\n",
      "Epoch 125/500\n",
      "804/804 [==============================] - 1s 762us/step - loss: 0.5352 - accuracy: 0.7373\n",
      "Epoch 126/500\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5346 - accuracy: 0.7362\n",
      "Epoch 127/500\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5344 - accuracy: 0.7353\n",
      "Epoch 128/500\n",
      "804/804 [==============================] - 1s 807us/step - loss: 0.5339 - accuracy: 0.7369\n",
      "Epoch 129/500\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5353 - accuracy: 0.7362\n",
      "Epoch 130/500\n",
      "804/804 [==============================] - 1s 727us/step - loss: 0.5340 - accuracy: 0.7367\n",
      "Epoch 131/500\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5342 - accuracy: 0.7374\n",
      "Epoch 132/500\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5340 - accuracy: 0.7374\n",
      "Epoch 133/500\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5342 - accuracy: 0.7383\n",
      "Epoch 134/500\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5335 - accuracy: 0.7369\n",
      "Epoch 135/500\n",
      "804/804 [==============================] - 1s 709us/step - loss: 0.5339 - accuracy: 0.7381\n",
      "Epoch 136/500\n",
      "804/804 [==============================] - 1s 715us/step - loss: 0.5338 - accuracy: 0.7362\n",
      "Epoch 137/500\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5340 - accuracy: 0.7364\n",
      "Epoch 138/500\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5332 - accuracy: 0.7365\n",
      "Epoch 139/500\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5339 - accuracy: 0.7358\n",
      "Epoch 140/500\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5327 - accuracy: 0.7375\n",
      "Epoch 141/500\n",
      "804/804 [==============================] - 1s 753us/step - loss: 0.5326 - accuracy: 0.7375\n",
      "Epoch 142/500\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5327 - accuracy: 0.7362\n",
      "Epoch 143/500\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5328 - accuracy: 0.7377\n",
      "Epoch 144/500\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5331 - accuracy: 0.7389\n",
      "Epoch 145/500\n",
      "804/804 [==============================] - 1s 767us/step - loss: 0.5328 - accuracy: 0.7365\n",
      "Epoch 146/500\n",
      "804/804 [==============================] - 1s 762us/step - loss: 0.5340 - accuracy: 0.7372\n",
      "Epoch 147/500\n",
      "804/804 [==============================] - 1s 766us/step - loss: 0.5330 - accuracy: 0.7378\n",
      "Epoch 148/500\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.5324 - accuracy: 0.7377\n",
      "Epoch 149/500\n",
      "804/804 [==============================] - 1s 782us/step - loss: 0.5317 - accuracy: 0.7383\n",
      "Epoch 150/500\n",
      "804/804 [==============================] - 1s 809us/step - loss: 0.5325 - accuracy: 0.7354\n",
      "Epoch 151/500\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5314 - accuracy: 0.7383\n",
      "Epoch 152/500\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5318 - accuracy: 0.7383\n",
      "Epoch 153/500\n",
      "804/804 [==============================] - 1s 770us/step - loss: 0.5318 - accuracy: 0.7399\n",
      "Epoch 154/500\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5315 - accuracy: 0.7372\n",
      "Epoch 155/500\n",
      "804/804 [==============================] - 1s 770us/step - loss: 0.5314 - accuracy: 0.7387\n",
      "Epoch 156/500\n",
      "804/804 [==============================] - 1s 812us/step - loss: 0.5331 - accuracy: 0.7388\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 760us/step - loss: 0.5326 - accuracy: 0.7388\n",
      "Epoch 158/500\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5319 - accuracy: 0.7392\n",
      "Epoch 159/500\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5324 - accuracy: 0.7382\n",
      "Epoch 160/500\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5316 - accuracy: 0.7386\n",
      "Epoch 161/500\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5315 - accuracy: 0.7391\n",
      "Epoch 162/500\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5319 - accuracy: 0.7383\n",
      "Epoch 163/500\n",
      "804/804 [==============================] - 1s 927us/step - loss: 0.5320 - accuracy: 0.7382\n",
      "Epoch 164/500\n",
      "804/804 [==============================] - 1s 923us/step - loss: 0.5315 - accuracy: 0.7384\n",
      "Epoch 165/500\n",
      "804/804 [==============================] - 1s 941us/step - loss: 0.5302 - accuracy: 0.7378\n",
      "Epoch 166/500\n",
      "804/804 [==============================] - 1s 819us/step - loss: 0.5299 - accuracy: 0.7385\n",
      "Epoch 167/500\n",
      "804/804 [==============================] - 1s 886us/step - loss: 0.5301 - accuracy: 0.7416\n",
      "Epoch 168/500\n",
      "804/804 [==============================] - 1s 831us/step - loss: 0.5304 - accuracy: 0.7386\n",
      "Epoch 169/500\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5303 - accuracy: 0.7402\n",
      "Epoch 170/500\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5301 - accuracy: 0.7392\n",
      "Epoch 171/500\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5301 - accuracy: 0.7385\n",
      "Epoch 172/500\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5294 - accuracy: 0.7392\n",
      "Epoch 173/500\n",
      "804/804 [==============================] - 1s 756us/step - loss: 0.5301 - accuracy: 0.7395\n",
      "Epoch 174/500\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5300 - accuracy: 0.7392\n",
      "Epoch 175/500\n",
      "804/804 [==============================] - 1s 753us/step - loss: 0.5295 - accuracy: 0.7404\n",
      "Epoch 176/500\n",
      "804/804 [==============================] - 1s 760us/step - loss: 0.5298 - accuracy: 0.7395\n",
      "Epoch 177/500\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5299 - accuracy: 0.7381\n",
      "Epoch 178/500\n",
      "804/804 [==============================] - 1s 866us/step - loss: 0.5300 - accuracy: 0.7388\n",
      "Epoch 179/500\n",
      "804/804 [==============================] - 1s 739us/step - loss: 0.5294 - accuracy: 0.7414\n",
      "Epoch 180/500\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5291 - accuracy: 0.7397\n",
      "Epoch 181/500\n",
      "804/804 [==============================] - 1s 774us/step - loss: 0.5295 - accuracy: 0.7396\n",
      "Epoch 182/500\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5294 - accuracy: 0.7390\n",
      "Epoch 183/500\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5286 - accuracy: 0.7404\n",
      "Epoch 184/500\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.5294 - accuracy: 0.7393\n",
      "Epoch 185/500\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5289 - accuracy: 0.7401\n",
      "Epoch 186/500\n",
      "804/804 [==============================] - 1s 793us/step - loss: 0.5285 - accuracy: 0.7404\n",
      "Epoch 187/500\n",
      "804/804 [==============================] - 1s 776us/step - loss: 0.5286 - accuracy: 0.7404\n",
      "Epoch 188/500\n",
      "804/804 [==============================] - 1s 799us/step - loss: 0.5289 - accuracy: 0.7406\n",
      "Epoch 189/500\n",
      "804/804 [==============================] - 1s 774us/step - loss: 0.5286 - accuracy: 0.7391\n",
      "Epoch 190/500\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5291 - accuracy: 0.7403\n",
      "Epoch 191/500\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5291 - accuracy: 0.7406\n",
      "Epoch 192/500\n",
      "804/804 [==============================] - 1s 758us/step - loss: 0.5279 - accuracy: 0.7412\n",
      "Epoch 193/500\n",
      "804/804 [==============================] - 1s 752us/step - loss: 0.5280 - accuracy: 0.7411\n",
      "Epoch 194/500\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5281 - accuracy: 0.7410\n",
      "Epoch 195/500\n",
      "804/804 [==============================] - 1s 760us/step - loss: 0.5276 - accuracy: 0.7411\n",
      "Epoch 196/500\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5282 - accuracy: 0.7408\n",
      "Epoch 197/500\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5289 - accuracy: 0.7403\n",
      "Epoch 198/500\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5284 - accuracy: 0.7404\n",
      "Epoch 199/500\n",
      "804/804 [==============================] - 1s 718us/step - loss: 0.5275 - accuracy: 0.7413\n",
      "Epoch 200/500\n",
      "804/804 [==============================] - 1s 715us/step - loss: 0.5282 - accuracy: 0.7409\n",
      "Epoch 201/500\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5279 - accuracy: 0.7397\n",
      "Epoch 202/500\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5283 - accuracy: 0.7415\n",
      "Epoch 203/500\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5279 - accuracy: 0.7406\n",
      "Epoch 204/500\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5275 - accuracy: 0.7405\n",
      "Epoch 205/500\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5274 - accuracy: 0.7418\n",
      "Epoch 206/500\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5272 - accuracy: 0.7413\n",
      "Epoch 207/500\n",
      "804/804 [==============================] - 1s 707us/step - loss: 0.5278 - accuracy: 0.7432\n",
      "Epoch 208/500\n",
      "804/804 [==============================] - 1s 713us/step - loss: 0.5266 - accuracy: 0.7416\n",
      "Epoch 209/500\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5275 - accuracy: 0.7418\n",
      "Epoch 210/500\n",
      "804/804 [==============================] - 1s 764us/step - loss: 0.5280 - accuracy: 0.7401\n",
      "Epoch 211/500\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5281 - accuracy: 0.7411\n",
      "Epoch 212/500\n",
      "804/804 [==============================] - 1s 824us/step - loss: 0.5268 - accuracy: 0.7409\n",
      "Epoch 213/500\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5271 - accuracy: 0.7411\n",
      "Epoch 214/500\n",
      "804/804 [==============================] - 1s 780us/step - loss: 0.5280 - accuracy: 0.7410\n",
      "Epoch 215/500\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5265 - accuracy: 0.7413\n",
      "Epoch 216/500\n",
      "804/804 [==============================] - 1s 756us/step - loss: 0.5270 - accuracy: 0.7418\n",
      "Epoch 217/500\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5272 - accuracy: 0.7410\n",
      "Epoch 218/500\n",
      "804/804 [==============================] - 1s 757us/step - loss: 0.5259 - accuracy: 0.7421\n",
      "Epoch 219/500\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5268 - accuracy: 0.7418\n",
      "Epoch 220/500\n",
      "804/804 [==============================] - 1s 753us/step - loss: 0.5264 - accuracy: 0.7413\n",
      "Epoch 221/500\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5278 - accuracy: 0.7416\n",
      "Epoch 222/500\n",
      "804/804 [==============================] - 1s 762us/step - loss: 0.5265 - accuracy: 0.7417\n",
      "Epoch 223/500\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5267 - accuracy: 0.7420\n",
      "Epoch 224/500\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5260 - accuracy: 0.7416\n",
      "Epoch 225/500\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5268 - accuracy: 0.7405\n",
      "Epoch 226/500\n",
      "804/804 [==============================] - 1s 774us/step - loss: 0.5264 - accuracy: 0.7414\n",
      "Epoch 227/500\n",
      "804/804 [==============================] - 1s 764us/step - loss: 0.5258 - accuracy: 0.7428\n",
      "Epoch 228/500\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5268 - accuracy: 0.7408\n",
      "Epoch 229/500\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5256 - accuracy: 0.7417\n",
      "Epoch 230/500\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5256 - accuracy: 0.7409\n",
      "Epoch 231/500\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5253 - accuracy: 0.7435\n",
      "Epoch 232/500\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5258 - accuracy: 0.7427\n",
      "Epoch 233/500\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5269 - accuracy: 0.7424\n",
      "Epoch 234/500\n",
      "804/804 [==============================] - 1s 756us/step - loss: 0.5255 - accuracy: 0.7431\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 746us/step - loss: 0.5259 - accuracy: 0.7428\n",
      "Epoch 236/500\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5254 - accuracy: 0.7427\n",
      "Epoch 237/500\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5254 - accuracy: 0.7412\n",
      "Epoch 238/500\n",
      "804/804 [==============================] - 1s 739us/step - loss: 0.5262 - accuracy: 0.7419\n",
      "Epoch 239/500\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5260 - accuracy: 0.7428\n",
      "Epoch 240/500\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5252 - accuracy: 0.7425\n",
      "Epoch 241/500\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5251 - accuracy: 0.7424\n",
      "Epoch 242/500\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5249 - accuracy: 0.7418\n",
      "Epoch 243/500\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5252 - accuracy: 0.7420\n",
      "Epoch 244/500\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5244 - accuracy: 0.7438\n",
      "Epoch 245/500\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5253 - accuracy: 0.7428\n",
      "Epoch 246/500\n",
      "804/804 [==============================] - 1s 812us/step - loss: 0.5245 - accuracy: 0.7430\n",
      "Epoch 247/500\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5245 - accuracy: 0.7418\n",
      "Epoch 248/500\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5252 - accuracy: 0.7425\n",
      "Epoch 249/500\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5244 - accuracy: 0.7431\n",
      "Epoch 250/500\n",
      "804/804 [==============================] - 1s 766us/step - loss: 0.5249 - accuracy: 0.7433\n",
      "Epoch 251/500\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5246 - accuracy: 0.7428\n",
      "Epoch 252/500\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5248 - accuracy: 0.7436\n",
      "Epoch 253/500\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5241 - accuracy: 0.7437\n",
      "Epoch 254/500\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5254 - accuracy: 0.7418\n",
      "Epoch 255/500\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5241 - accuracy: 0.7439\n",
      "Epoch 256/500\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5252 - accuracy: 0.7438\n",
      "Epoch 257/500\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5243 - accuracy: 0.7432\n",
      "Epoch 258/500\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5238 - accuracy: 0.7430\n",
      "Epoch 259/500\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5247 - accuracy: 0.7425\n",
      "Epoch 260/500\n",
      "804/804 [==============================] - 1s 799us/step - loss: 0.5244 - accuracy: 0.7442\n",
      "Epoch 261/500\n",
      "804/804 [==============================] - 1s 769us/step - loss: 0.5246 - accuracy: 0.7438\n",
      "Epoch 262/500\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5234 - accuracy: 0.7434\n",
      "Epoch 263/500\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5247 - accuracy: 0.7439\n",
      "Epoch 264/500\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5229 - accuracy: 0.7444\n",
      "Epoch 265/500\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5257 - accuracy: 0.7420\n",
      "Epoch 266/500\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5243 - accuracy: 0.7427\n",
      "Epoch 267/500\n",
      "804/804 [==============================] - 1s 764us/step - loss: 0.5238 - accuracy: 0.7443\n",
      "Epoch 268/500\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5247 - accuracy: 0.7438\n",
      "Epoch 269/500\n",
      "804/804 [==============================] - 1s 778us/step - loss: 0.5233 - accuracy: 0.7437\n",
      "Epoch 270/500\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5241 - accuracy: 0.7431\n",
      "Epoch 271/500\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5239 - accuracy: 0.7435\n",
      "Epoch 272/500\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5233 - accuracy: 0.7434\n",
      "Epoch 273/500\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5233 - accuracy: 0.7441\n",
      "Epoch 274/500\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5235 - accuracy: 0.7437\n",
      "Epoch 275/500\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5222 - accuracy: 0.7449\n",
      "Epoch 276/500\n",
      "804/804 [==============================] - 1s 707us/step - loss: 0.5238 - accuracy: 0.7433\n",
      "Epoch 277/500\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5232 - accuracy: 0.7449\n",
      "Epoch 278/500\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5228 - accuracy: 0.7440\n",
      "Epoch 279/500\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5239 - accuracy: 0.7432\n",
      "Epoch 280/500\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5246 - accuracy: 0.7439\n",
      "Epoch 281/500\n",
      "804/804 [==============================] - 1s 715us/step - loss: 0.5236 - accuracy: 0.7446\n",
      "Epoch 282/500\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5229 - accuracy: 0.7434\n",
      "Epoch 283/500\n",
      "804/804 [==============================] - 1s 698us/step - loss: 0.5230 - accuracy: 0.7444\n",
      "Epoch 284/500\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5234 - accuracy: 0.7430\n",
      "Epoch 285/500\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5230 - accuracy: 0.7440\n",
      "Epoch 286/500\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5234 - accuracy: 0.7439\n",
      "Epoch 287/500\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5229 - accuracy: 0.7448\n",
      "Epoch 288/500\n",
      "804/804 [==============================] - 1s 765us/step - loss: 0.5244 - accuracy: 0.7440\n",
      "Epoch 289/500\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5219 - accuracy: 0.7434\n",
      "Epoch 290/500\n",
      "804/804 [==============================] - 1s 776us/step - loss: 0.5226 - accuracy: 0.7437\n",
      "Epoch 291/500\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5235 - accuracy: 0.7440\n",
      "Epoch 292/500\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5225 - accuracy: 0.7456\n",
      "Epoch 293/500\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5231 - accuracy: 0.7437\n",
      "Epoch 294/500\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5227 - accuracy: 0.7435\n",
      "Epoch 295/500\n",
      "804/804 [==============================] - 1s 806us/step - loss: 0.5223 - accuracy: 0.7460\n",
      "Epoch 296/500\n",
      "804/804 [==============================] - 1s 807us/step - loss: 0.5233 - accuracy: 0.7438\n",
      "Epoch 297/500\n",
      "804/804 [==============================] - 1s 780us/step - loss: 0.5222 - accuracy: 0.7435\n",
      "Epoch 298/500\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5231 - accuracy: 0.7456\n",
      "Epoch 299/500\n",
      "804/804 [==============================] - 1s 754us/step - loss: 0.5235 - accuracy: 0.7444\n",
      "Epoch 300/500\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5219 - accuracy: 0.7446\n",
      "Epoch 301/500\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5228 - accuracy: 0.7446\n",
      "Epoch 302/500\n",
      "804/804 [==============================] - 1s 766us/step - loss: 0.5233 - accuracy: 0.7424\n",
      "Epoch 303/500\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5218 - accuracy: 0.7436\n",
      "Epoch 304/500\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5233 - accuracy: 0.7437\n",
      "Epoch 305/500\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5222 - accuracy: 0.7463\n",
      "Epoch 306/500\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5220 - accuracy: 0.7465\n",
      "Epoch 307/500\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5225 - accuracy: 0.7439\n",
      "Epoch 308/500\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5228 - accuracy: 0.7426\n",
      "Epoch 309/500\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5221 - accuracy: 0.7427\n",
      "Epoch 310/500\n",
      "804/804 [==============================] - 1s 757us/step - loss: 0.5219 - accuracy: 0.7435\n",
      "Epoch 311/500\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5219 - accuracy: 0.7429\n",
      "Epoch 312/500\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5210 - accuracy: 0.7451\n",
      "Epoch 313/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 824us/step - loss: 0.5219 - accuracy: 0.7445\n",
      "Epoch 314/500\n",
      "804/804 [==============================] - 1s 763us/step - loss: 0.5221 - accuracy: 0.7442\n",
      "Epoch 315/500\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5216 - accuracy: 0.7448\n",
      "Epoch 316/500\n",
      "804/804 [==============================] - 1s 752us/step - loss: 0.5220 - accuracy: 0.7435\n",
      "Epoch 317/500\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5217 - accuracy: 0.7448\n",
      "Epoch 318/500\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5226 - accuracy: 0.7439\n",
      "Epoch 319/500\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5229 - accuracy: 0.7441\n",
      "Epoch 320/500\n",
      "804/804 [==============================] - 1s 755us/step - loss: 0.5223 - accuracy: 0.7452\n",
      "Epoch 321/500\n",
      "804/804 [==============================] - 1s 769us/step - loss: 0.5214 - accuracy: 0.7435\n",
      "Epoch 322/500\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5213 - accuracy: 0.7438\n",
      "Epoch 323/500\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5217 - accuracy: 0.7441\n",
      "Epoch 324/500\n",
      "804/804 [==============================] - 1s 758us/step - loss: 0.5223 - accuracy: 0.7442\n",
      "Epoch 325/500\n",
      "804/804 [==============================] - 1s 754us/step - loss: 0.5211 - accuracy: 0.7458\n",
      "Epoch 326/500\n",
      "804/804 [==============================] - 1s 753us/step - loss: 0.5216 - accuracy: 0.7452\n",
      "Epoch 327/500\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5214 - accuracy: 0.7440\n",
      "Epoch 328/500\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5207 - accuracy: 0.7441\n",
      "Epoch 329/500\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5214 - accuracy: 0.7447\n",
      "Epoch 330/500\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5214 - accuracy: 0.7471\n",
      "Epoch 331/500\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5225 - accuracy: 0.7450\n",
      "Epoch 332/500\n",
      "804/804 [==============================] - 1s 705us/step - loss: 0.5214 - accuracy: 0.7457\n",
      "Epoch 333/500\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5224 - accuracy: 0.7442\n",
      "Epoch 334/500\n",
      "804/804 [==============================] - 1s 723us/step - loss: 0.5210 - accuracy: 0.7453\n",
      "Epoch 335/500\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5214 - accuracy: 0.7452\n",
      "Epoch 336/500\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5216 - accuracy: 0.7432\n",
      "Epoch 337/500\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5213 - accuracy: 0.7463\n",
      "Epoch 338/500\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5208 - accuracy: 0.7447\n",
      "Epoch 339/500\n",
      "804/804 [==============================] - 1s 705us/step - loss: 0.5219 - accuracy: 0.7445\n",
      "Epoch 340/500\n",
      "804/804 [==============================] - 1s 715us/step - loss: 0.5216 - accuracy: 0.7440\n",
      "Epoch 341/500\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5210 - accuracy: 0.7456\n",
      "Epoch 342/500\n",
      "804/804 [==============================] - 1s 706us/step - loss: 0.5208 - accuracy: 0.7457\n",
      "Epoch 343/500\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5219 - accuracy: 0.7446\n",
      "Epoch 344/500\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5208 - accuracy: 0.7443\n",
      "Epoch 345/500\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5210 - accuracy: 0.7462\n",
      "Epoch 346/500\n",
      "804/804 [==============================] - 1s 711us/step - loss: 0.5230 - accuracy: 0.7452\n",
      "Epoch 347/500\n",
      "804/804 [==============================] - 1s 712us/step - loss: 0.5208 - accuracy: 0.7458\n",
      "Epoch 348/500\n",
      "804/804 [==============================] - 1s 782us/step - loss: 0.5203 - accuracy: 0.7455\n",
      "Epoch 349/500\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5209 - accuracy: 0.7446\n",
      "Epoch 350/500\n",
      "804/804 [==============================] - 1s 756us/step - loss: 0.5216 - accuracy: 0.7448\n",
      "Epoch 351/500\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5204 - accuracy: 0.7450\n",
      "Epoch 352/500\n",
      "804/804 [==============================] - 1s 771us/step - loss: 0.5207 - accuracy: 0.7458\n",
      "Epoch 353/500\n",
      "804/804 [==============================] - 1s 762us/step - loss: 0.5209 - accuracy: 0.7442\n",
      "Epoch 354/500\n",
      "804/804 [==============================] - 1s 778us/step - loss: 0.5199 - accuracy: 0.7475\n",
      "Epoch 355/500\n",
      "804/804 [==============================] - 1s 754us/step - loss: 0.5203 - accuracy: 0.7458\n",
      "Epoch 356/500\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5212 - accuracy: 0.7450\n",
      "Epoch 357/500\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5209 - accuracy: 0.7457\n",
      "Epoch 358/500\n",
      "804/804 [==============================] - 1s 782us/step - loss: 0.5195 - accuracy: 0.7454\n",
      "Epoch 359/500\n",
      "804/804 [==============================] - 1s 780us/step - loss: 0.5198 - accuracy: 0.7446\n",
      "Epoch 360/500\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5206 - accuracy: 0.7442\n",
      "Epoch 361/500\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.5207 - accuracy: 0.7444\n",
      "Epoch 362/500\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5197 - accuracy: 0.7465\n",
      "Epoch 363/500\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5217 - accuracy: 0.7435\n",
      "Epoch 364/500\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5205 - accuracy: 0.7446\n",
      "Epoch 365/500\n",
      "804/804 [==============================] - 1s 817us/step - loss: 0.5198 - accuracy: 0.7453\n",
      "Epoch 366/500\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5189 - accuracy: 0.7454\n",
      "Epoch 367/500\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5199 - accuracy: 0.7457\n",
      "Epoch 368/500\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5203 - accuracy: 0.7457\n",
      "Epoch 369/500\n",
      "804/804 [==============================] - 1s 756us/step - loss: 0.5193 - accuracy: 0.7460\n",
      "Epoch 370/500\n",
      "804/804 [==============================] - 1s 880us/step - loss: 0.5203 - accuracy: 0.7441\n",
      "Epoch 371/500\n",
      "804/804 [==============================] - 1s 774us/step - loss: 0.5201 - accuracy: 0.7457\n",
      "Epoch 372/500\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5193 - accuracy: 0.7458\n",
      "Epoch 373/500\n",
      "804/804 [==============================] - 1s 879us/step - loss: 0.5187 - accuracy: 0.7462\n",
      "Epoch 374/500\n",
      "804/804 [==============================] - 1s 789us/step - loss: 0.5191 - accuracy: 0.7461\n",
      "Epoch 375/500\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5193 - accuracy: 0.7468\n",
      "Epoch 376/500\n",
      "804/804 [==============================] - 1s 767us/step - loss: 0.5197 - accuracy: 0.7447\n",
      "Epoch 377/500\n",
      "804/804 [==============================] - 1s 769us/step - loss: 0.5206 - accuracy: 0.7476\n",
      "Epoch 378/500\n",
      "804/804 [==============================] - 1s 771us/step - loss: 0.5194 - accuracy: 0.7458\n",
      "Epoch 379/500\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5198 - accuracy: 0.7450\n",
      "Epoch 380/500\n",
      "804/804 [==============================] - 1s 760us/step - loss: 0.5197 - accuracy: 0.7447\n",
      "Epoch 381/500\n",
      "804/804 [==============================] - 1s 804us/step - loss: 0.5207 - accuracy: 0.7453\n",
      "Epoch 382/500\n",
      "804/804 [==============================] - 1s 766us/step - loss: 0.5192 - accuracy: 0.7447\n",
      "Epoch 383/500\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5204 - accuracy: 0.7456\n",
      "Epoch 384/500\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5203 - accuracy: 0.7453\n",
      "Epoch 385/500\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5185 - accuracy: 0.7455\n",
      "Epoch 386/500\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5192 - accuracy: 0.7461\n",
      "Epoch 387/500\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5193 - accuracy: 0.7458\n",
      "Epoch 388/500\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5197 - accuracy: 0.7451\n",
      "Epoch 389/500\n",
      "804/804 [==============================] - 1s 765us/step - loss: 0.5192 - accuracy: 0.7457\n",
      "Epoch 390/500\n",
      "804/804 [==============================] - 1s 752us/step - loss: 0.5192 - accuracy: 0.7457\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 779us/step - loss: 0.5193 - accuracy: 0.7464\n",
      "Epoch 392/500\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5188 - accuracy: 0.7462\n",
      "Epoch 393/500\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5187 - accuracy: 0.7477\n",
      "Epoch 394/500\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5188 - accuracy: 0.7467\n",
      "Epoch 395/500\n",
      "804/804 [==============================] - 1s 765us/step - loss: 0.5195 - accuracy: 0.7461\n",
      "Epoch 396/500\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5198 - accuracy: 0.7458\n",
      "Epoch 397/500\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5192 - accuracy: 0.7472\n",
      "Epoch 398/500\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.5199 - accuracy: 0.7445\n",
      "Epoch 399/500\n",
      "804/804 [==============================] - 1s 701us/step - loss: 0.5191 - accuracy: 0.7456\n",
      "Epoch 400/500\n",
      "804/804 [==============================] - 1s 713us/step - loss: 0.5180 - accuracy: 0.7492\n",
      "Epoch 401/500\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5185 - accuracy: 0.7471\n",
      "Epoch 402/500\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5188 - accuracy: 0.7455\n",
      "Epoch 403/500\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5202 - accuracy: 0.7447\n",
      "Epoch 404/500\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5193 - accuracy: 0.7467\n",
      "Epoch 405/500\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5188 - accuracy: 0.7469\n",
      "Epoch 406/500\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5199 - accuracy: 0.7463\n",
      "Epoch 407/500\n",
      "804/804 [==============================] - 1s 762us/step - loss: 0.5205 - accuracy: 0.7461\n",
      "Epoch 408/500\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5198 - accuracy: 0.7447\n",
      "Epoch 409/500\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5199 - accuracy: 0.7466\n",
      "Epoch 410/500\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5196 - accuracy: 0.7452\n",
      "Epoch 411/500\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5192 - accuracy: 0.7467\n",
      "Epoch 412/500\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5187 - accuracy: 0.7471\n",
      "Epoch 413/500\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5196 - accuracy: 0.7457\n",
      "Epoch 414/500\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5182 - accuracy: 0.7467\n",
      "Epoch 415/500\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5179 - accuracy: 0.7478\n",
      "Epoch 416/500\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5188 - accuracy: 0.7475\n",
      "Epoch 417/500\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5191 - accuracy: 0.7455\n",
      "Epoch 418/500\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5176 - accuracy: 0.7465\n",
      "Epoch 419/500\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5195 - accuracy: 0.7452\n",
      "Epoch 420/500\n",
      "804/804 [==============================] - 1s 775us/step - loss: 0.5172 - accuracy: 0.7478\n",
      "Epoch 421/500\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5185 - accuracy: 0.7467\n",
      "Epoch 422/500\n",
      "804/804 [==============================] - 1s 767us/step - loss: 0.5194 - accuracy: 0.7466\n",
      "Epoch 423/500\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.5188 - accuracy: 0.7467\n",
      "Epoch 424/500\n",
      "804/804 [==============================] - 1s 810us/step - loss: 0.5184 - accuracy: 0.7451\n",
      "Epoch 425/500\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5192 - accuracy: 0.7455\n",
      "Epoch 426/500\n",
      "804/804 [==============================] - 1s 784us/step - loss: 0.5182 - accuracy: 0.7472\n",
      "Epoch 427/500\n",
      "804/804 [==============================] - 1s 771us/step - loss: 0.5184 - accuracy: 0.7460\n",
      "Epoch 428/500\n",
      "804/804 [==============================] - 1s 760us/step - loss: 0.5195 - accuracy: 0.7437\n",
      "Epoch 429/500\n",
      "804/804 [==============================] - 1s 816us/step - loss: 0.5192 - accuracy: 0.7465\n",
      "Epoch 430/500\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5190 - accuracy: 0.7456\n",
      "Epoch 431/500\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5175 - accuracy: 0.7480\n",
      "Epoch 432/500\n",
      "804/804 [==============================] - 1s 769us/step - loss: 0.5179 - accuracy: 0.7481\n",
      "Epoch 433/500\n",
      "804/804 [==============================] - 1s 727us/step - loss: 0.5179 - accuracy: 0.7470\n",
      "Epoch 434/500\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5185 - accuracy: 0.7471\n",
      "Epoch 435/500\n",
      "804/804 [==============================] - 1s 707us/step - loss: 0.5177 - accuracy: 0.7455\n",
      "Epoch 436/500\n",
      "804/804 [==============================] - 1s 691us/step - loss: 0.5176 - accuracy: 0.7467\n",
      "Epoch 437/500\n",
      "804/804 [==============================] - 1s 697us/step - loss: 0.5183 - accuracy: 0.7456\n",
      "Epoch 438/500\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5179 - accuracy: 0.7474\n",
      "Epoch 439/500\n",
      "804/804 [==============================] - 1s 705us/step - loss: 0.5183 - accuracy: 0.7462\n",
      "Epoch 440/500\n",
      "804/804 [==============================] - 1s 697us/step - loss: 0.5178 - accuracy: 0.7479\n",
      "Epoch 441/500\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5179 - accuracy: 0.7476\n",
      "Epoch 442/500\n",
      "804/804 [==============================] - 1s 714us/step - loss: 0.5183 - accuracy: 0.7463\n",
      "Epoch 443/500\n",
      "804/804 [==============================] - 1s 766us/step - loss: 0.5178 - accuracy: 0.7476\n",
      "Epoch 444/500\n",
      "804/804 [==============================] - 1s 727us/step - loss: 0.5177 - accuracy: 0.7476\n",
      "Epoch 445/500\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5179 - accuracy: 0.7474\n",
      "Epoch 446/500\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5184 - accuracy: 0.7469\n",
      "Epoch 447/500\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5180 - accuracy: 0.7451\n",
      "Epoch 448/500\n",
      "804/804 [==============================] - 1s 808us/step - loss: 0.5169 - accuracy: 0.7480\n",
      "Epoch 449/500\n",
      "804/804 [==============================] - 1s 823us/step - loss: 0.5168 - accuracy: 0.7485\n",
      "Epoch 450/500\n",
      "804/804 [==============================] - 1s 762us/step - loss: 0.5180 - accuracy: 0.7474\n",
      "Epoch 451/500\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5167 - accuracy: 0.7474\n",
      "Epoch 452/500\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5175 - accuracy: 0.7466\n",
      "Epoch 453/500\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5170 - accuracy: 0.7459\n",
      "Epoch 454/500\n",
      "804/804 [==============================] - 1s 764us/step - loss: 0.5175 - accuracy: 0.7470\n",
      "Epoch 455/500\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5180 - accuracy: 0.7474\n",
      "Epoch 456/500\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5167 - accuracy: 0.7470\n",
      "Epoch 457/500\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5171 - accuracy: 0.7467\n",
      "Epoch 458/500\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5179 - accuracy: 0.7465\n",
      "Epoch 459/500\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5175 - accuracy: 0.7464\n",
      "Epoch 460/500\n",
      "804/804 [==============================] - 1s 752us/step - loss: 0.5180 - accuracy: 0.7465\n",
      "Epoch 461/500\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5167 - accuracy: 0.7483\n",
      "Epoch 462/500\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5176 - accuracy: 0.7473\n",
      "Epoch 463/500\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5180 - accuracy: 0.7453\n",
      "Epoch 464/500\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5175 - accuracy: 0.7463\n",
      "Epoch 465/500\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5174 - accuracy: 0.7468\n",
      "Epoch 466/500\n",
      "804/804 [==============================] - 1s 836us/step - loss: 0.5172 - accuracy: 0.7460\n",
      "Epoch 467/500\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5171 - accuracy: 0.7468\n",
      "Epoch 468/500\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5176 - accuracy: 0.7455\n",
      "Epoch 469/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 747us/step - loss: 0.5177 - accuracy: 0.7467\n",
      "Epoch 470/500\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5176 - accuracy: 0.7465\n",
      "Epoch 471/500\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5180 - accuracy: 0.7448\n",
      "Epoch 472/500\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5164 - accuracy: 0.7474\n",
      "Epoch 473/500\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5181 - accuracy: 0.7467\n",
      "Epoch 474/500\n",
      "804/804 [==============================] - 1s 755us/step - loss: 0.5166 - accuracy: 0.7468\n",
      "Epoch 475/500\n",
      "804/804 [==============================] - 1s 739us/step - loss: 0.5175 - accuracy: 0.7471\n",
      "Epoch 476/500\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5167 - accuracy: 0.7473\n",
      "Epoch 477/500\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5176 - accuracy: 0.7463\n",
      "Epoch 478/500\n",
      "804/804 [==============================] - 1s 752us/step - loss: 0.5160 - accuracy: 0.7476\n",
      "Epoch 479/500\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5161 - accuracy: 0.7479\n",
      "Epoch 480/500\n",
      "804/804 [==============================] - 1s 771us/step - loss: 0.5172 - accuracy: 0.7449\n",
      "Epoch 481/500\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5174 - accuracy: 0.7472\n",
      "Epoch 482/500\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5161 - accuracy: 0.7469\n",
      "Epoch 483/500\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5185 - accuracy: 0.7470\n",
      "Epoch 484/500\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5166 - accuracy: 0.7483\n",
      "Epoch 485/500\n",
      "804/804 [==============================] - 1s 752us/step - loss: 0.5162 - accuracy: 0.7464\n",
      "Epoch 486/500\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5168 - accuracy: 0.7467\n",
      "Epoch 487/500\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5166 - accuracy: 0.7456\n",
      "Epoch 488/500\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5166 - accuracy: 0.7463\n",
      "Epoch 489/500\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5165 - accuracy: 0.7451\n",
      "Epoch 490/500\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5162 - accuracy: 0.7472\n",
      "Epoch 491/500\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5157 - accuracy: 0.7474\n",
      "Epoch 492/500\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5178 - accuracy: 0.7453\n",
      "Epoch 493/500\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5162 - accuracy: 0.7477\n",
      "Epoch 494/500\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5173 - accuracy: 0.7474\n",
      "Epoch 495/500\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5175 - accuracy: 0.7472\n",
      "Epoch 496/500\n",
      "804/804 [==============================] - 1s 718us/step - loss: 0.5173 - accuracy: 0.7465\n",
      "Epoch 497/500\n",
      "804/804 [==============================] - 1s 715us/step - loss: 0.5163 - accuracy: 0.7470\n",
      "Epoch 498/500\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5152 - accuracy: 0.7466\n",
      "Epoch 499/500\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5166 - accuracy: 0.7480\n",
      "Epoch 500/500\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5167 - accuracy: 0.7483\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5909 - accuracy: 0.7139\n",
      "Loss: 0.5909494161605835, Accuracy: 0.7139358520507812\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
